#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import csv
import logging
import os
import random
import re
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from urllib.parse import urljoin, urlparse

try:
    from curl_cffi import requests
    from fake_useragent import UserAgent
    from selectolax.parser import HTMLParser
    from dotenv import load_dotenv
    from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt")
    sys.exit(1)


class TGStatParser:
    def __init__(self, proxy: Optional[str] = None, delay_base: float = 0.8, delay_jitter: float = 0.4):
        self.base_url = "https://tgstat.ru"
        self.session = requests.Session(impersonate="chrome110")
        self.ua = UserAgent()
        self.delay_base = delay_base
        self.delay_jitter = delay_jitter
        self.proxy = proxy
        self.channels_data: Set[Tuple[str, int, str]] = set()  # title, subscribers, link
        self.chats_data: Set[Tuple[str, int, str]] = set()  # title, subscribers, link
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏
        if proxy:
            self.session.proxies = {"http": proxy, "https": proxy}
            
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.setup_logging()
        
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å"""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤
        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
        self.logger = logging.getLogger("tgstat_parser")
        self.logger.setLevel(logging.INFO)
        
        # –£–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
        self.logger.handlers = []
        
        # –§–æ—Ä–º–∞—Ç –¥–ª—è –ª–æ–≥–æ–≤
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        
        # –§–∞–π–ª–æ–≤—ã–π handler
        file_handler = logging.FileHandler(logs_dir / "app.log", encoding='utf-8')
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)
        
        # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
    def get_random_headers(self) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –∞–Ω—Ç–∏–±–æ—Ç –∑–∞—â–∏—Ç—ã"""
        return {
            "User-Agent": self.ua.random,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3",
            "Accept-Encoding": "gzip, deflate",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
        }

    def random_delay(self):
        """–°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å –¥–∂–∏—Ç—Ç–µ—Ä–æ–º"""
        delay = self.delay_base + random.uniform(0, self.delay_jitter)
        time.sleep(delay)

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10),
           retry=retry_if_exception_type((Exception,)))
    def make_request(self, url: str) -> Optional[requests.Response]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ HTTP –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ —Ä–µ—Ç—Ä–∞—è–º–∏"""
        try:
            headers = self.get_random_headers()
            self.logger.info(f"üåê –ó–∞–ø—Ä–æ—Å –∫: {url}")
            
            response = self.session.get(url, headers=headers, timeout=30)
            
            if response.status_code == 429:
                self.logger.warning("‚ö†Ô∏è Rate limit (429), —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É...")
                time.sleep(5 + random.uniform(0, 5))
                raise requests.RequestException("Rate limit exceeded")
            
            if response.status_code not in [200, 404]:
                self.logger.error(f"‚ùå HTTP {response.status_code}: {url}")
                response.raise_for_status()
                
            return response
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")
            raise

    def normalize_subscribers(self, text: str) -> int:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç"""
        if not text:
            return 0
            
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, —Ç–æ—á–µ–∫, –∑–∞–ø—è—Ç—ã—Ö –∏ –±—É–∫–≤ K/M
        text = re.sub(r'[^\d.,KMkm]', '', text.strip())
        
        if not text:
            return 0
            
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
        text = text.replace(',', '.')
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ K (—Ç—ã—Å—è—á–∏) –∏ M (–º–∏–ª–ª–∏–æ–Ω—ã)
            if text.lower().endswith('k'):
                number = float(text[:-1])
                return int(number * 1000)
            elif text.lower().endswith('m'):
                number = float(text[:-1]) 
                return int(number * 1000000)
            else:
                # –û–±—ã—á–Ω–æ–µ —á–∏—Å–ª–æ, —É–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç—ã—Å—è—á
                if '.' in text and len(text.split('.')[-1]) == 3:
                    # –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á
                    text = text.replace('.', '')
                return int(float(text))
        except (ValueError, IndexError):
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤: {text}")
            return 0

    def extract_telegram_link(self, card_html: str, tgstat_url: str = "") -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏ –Ω–∞ Telegram –∫–∞–Ω–∞–ª/—á–∞—Ç"""
        parser = HTMLParser(card_html)
        
        # –ò—â–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ t.me
        tme_links = parser.css('a[href*="t.me"]')
        if tme_links:
            href = tme_links[0].attributes.get('href', '')
            if href.startswith('https://t.me/'):
                return href
                
        # –ò—â–µ–º –≤ data-–∞—Ç—Ä–∏–±—É—Ç–∞—Ö –∏–ª–∏ —Å–∫—Ä—ã—Ç—ã—Ö –ø–æ–ª—è—Ö
        data_attrs = parser.css('[data-username]')
        if data_attrs:
            username = data_attrs[0].attributes.get('data-username', '').strip('@')
            if username:
                return f"https://t.me/{username}"
        
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ username —Ñ–æ—Ä–º–∞—Ç–∞ @username
        text_content = parser.text()
        username_match = re.search(r'@([a-zA-Z0-9_]+)', text_content)
        if username_match:
            username = username_match.group(1)
            return f"https://t.me/{username}"
            
        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º tgstat url —Å –ø–æ–º–µ—Ç–∫–æ–π
        if tgstat_url:
            return f"{tgstat_url} (tgstat)"
            
        return ""

    def parse_page(self, url: str) -> Tuple[List[Dict], bool]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞"""
        self.random_delay()
        
        try:
            response = self.make_request(url)
            if not response or response.status_code != 200:
                return [], False
                
            parser = HTMLParser(response.text)
            
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–∞–Ω–∞–ª–æ–≤/—á–∞—Ç–æ–≤
            cards = parser.css('.card, .channel-card, .chat-card, .peer-card')
            if not cards:
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                cards = parser.css('[data-peer-id], .peer-item, .rating-item')
                
            items = []
            for card in cards:
                try:
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                    title_elem = card.css_first('.card-title, .peer-title, .channel-title, h3, h4, .title')
                    if not title_elem:
                        title_elem = card.css_first('a[href*="/channel/"], a[href*="/chat/"]')
                    
                    if not title_elem:
                        continue
                        
                    title = title_elem.text(strip=True)
                    if not title:
                        continue
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
                    subscribers = 0
                    subscribers_elem = card.css_first('.subscribers, .members, .peer-subscribers, .count')
                    if subscribers_elem:
                        subscribers_text = subscribers_elem.text(strip=True)
                        subscribers = self.normalize_subscribers(subscribers_text)
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏
                    tgstat_link = ""
                    link_elem = card.css_first('a[href]')
                    if link_elem:
                        href = link_elem.attributes.get('href', '')
                        if href.startswith('/'):
                            tgstat_link = urljoin(self.base_url, href)
                        else:
                            tgstat_link = href
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º Telegram —Å—Å—ã–ª–∫—É
                    telegram_link = self.extract_telegram_link(card.html, tgstat_link)
                    if not telegram_link:
                        telegram_link = tgstat_link
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø (–∫–∞–Ω–∞–ª –∏–ª–∏ —á–∞—Ç) –ø–æ URL –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
                    is_channel = "/channel/" in tgstat_link or "–∫–∞–Ω–∞–ª" in title.lower()
                    
                    item = {
                        'title': title,
                        'subscribers': subscribers,
                        'link': telegram_link,
                        'type': 'channel' if is_channel else 'chat'
                    }
                    items.append(item)
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                    continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            has_next = bool(parser.css('a[href*="page="]:contains("–°–ª–µ–¥—É—é—â–∞—è"), .pagination .next, a.next'))
            
            self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            return items, has_next
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return [], False

    def build_url(self, category: str = "", url: str = "", page: int = 1, item_type: str = "channels") -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        if url:
            # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø—Ä—è–º–æ–π URL
            if "page=" in url:
                # –ó–∞–º–µ–Ω—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                return re.sub(r'page=\d+', f'page={page}', url)
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                separator = "&" if "?" in url else "?"
                return f"{url}{separator}page={page}"
        else:
            # –°—Ç—Ä–æ–∏–º URL –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            return f"{self.base_url}/ratings/{item_type}/{category}?page={page}"

    def parse_catalog(self, category: str = "", url: str = "", pages: int = 1, item_type: str = "channels"):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ç–∞–ª–æ–≥–∞"""
        self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥: –∫–∞—Ç–µ–≥–æ—Ä–∏—è='{category}', url='{url}', —Å—Ç—Ä–∞–Ω–∏—Ü={pages}, —Ç–∏–ø='{item_type}'")
        
        for page_num in range(1, pages + 1):
            page_url = self.build_url(category, url, page_num, item_type)
            self.logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{pages}: {page_url}")
            
            items, has_next = self.parse_page(page_url)
            
            if not items:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}, –∑–∞–≤–µ—Ä—à–∞–µ–º...")
                break
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π
            for item in items:
                data_tuple = (item['title'], item['subscribers'], item['link'])
                
                if item['type'] == 'channel':
                    self.channels_data.add(data_tuple)
                else:
                    self.chats_data.add(data_tuple)
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º
            if not has_next and page_num < pages:
                self.logger.info(f"üìÑ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ({page_num})")
                break
                
        self.logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ö–∞–Ω–∞–ª–æ–≤: {len(self.channels_data)}, —á–∞—Ç–æ–≤: {len(self.chats_data)}")

    def save_to_csv(self, output_dir: str = "./output"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV —Ñ–∞–π–ª—ã"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤
        if self.channels_data:
            channels_file = output_path / "channels.csv"
            with open(channels_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(['title', 'subscribers', 'link'])
                writer.writerows(sorted(self.channels_data, key=lambda x: x[1], reverse=True))
            self.logger.info(f"üíæ –ö–∞–Ω–∞–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {channels_file} ({len(self.channels_data)} –∑–∞–ø–∏—Å–µ–π)")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞—Ç–æ–≤
        if self.chats_data:
            chats_file = output_path / "chats.csv"
            with open(chats_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(['title', 'subscribers', 'link'])
                writer.writerows(sorted(self.chats_data, key=lambda x: x[1], reverse=True))
            self.logger.info(f"üíæ –ß–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {chats_file} ({len(self.chats_data)} –∑–∞–ø–∏—Å–µ–π)")


def main():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    load_dotenv()
    
    parser = argparse.ArgumentParser(description="–ü–∞—Ä—Å–µ—Ä –∫–∞—Ç–∞–ª–æ–≥–æ–≤ Telegram –Ω–∞ TGStat")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--url", help="–ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é TGStat")
    parser.add_argument("--category", help="–ö–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: news, travel)")
    parser.add_argument("--type", choices=["channels", "chats"], default="channels", 
                        help="–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    parser.add_argument("--pages", type=int, default=1, 
                        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    parser.add_argument("--outdir", default="./output", 
                        help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--delay", type=float, default=0.8, 
                        help="–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏")
    parser.add_argument("--proxy", help="–ü—Ä–æ–∫—Å–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    parser.add_argument("--self-check", action="store_true", 
                        help="–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 1 —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
    
    args = parser.parse_args()
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if not args.url and not args.category:
        print("‚ùå –û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ --url –∏–ª–∏ --category")
        sys.exit(1)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞—Ä–≥—É–º–µ–Ω—Ç > –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è)
    proxy = args.proxy or os.getenv('PROXY')
    delay_base = args.delay or float(os.getenv('REQUEST_DELAY_BASE', 0.8))
    delay_jitter = float(os.getenv('REQUEST_DELAY_JITTER', 0.4))
    
    # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    if args.self_check:
        print("üîç –†–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (1 —Å—Ç—Ä–∞–Ω–∏—Ü–∞)...")
        args.pages = 1
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
    tgstat = TGStatParser(proxy=proxy, delay_base=delay_base, delay_jitter=delay_jitter)
    
    try:
        # –ü–∞—Ä—Å–∏–Ω–≥
        tgstat.parse_catalog(
            category=args.category or "",
            url=args.url or "",
            pages=args.pages,
            item_type=args.type
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        tgstat.save_to_csv(args.outdir)
        
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.outdir}/")
        print(f"   üìä –ö–∞–Ω–∞–ª–æ–≤: {len(tgstat.channels_data)}")
        print(f"   üìä –ß–∞—Ç–æ–≤: {len(tgstat.chats_data)}")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        tgstat.save_to_csv(args.outdir)
        sys.exit(0)
    except Exception as e:
        tgstat.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()